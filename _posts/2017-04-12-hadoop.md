---
title: Hadoop 정리노트
description: 'Hadoop 공부하면서 계속 정리해놓는 노트입니다.'
header: Hadoop 정리노트
---


> 본 포스트는 Apache Hadoop 을 공부하면서 드문드문 계속 정리해 업데이트 되는 노트 입니다.

### Hadoop?
- 대용량 데이터를 처리하는 분산 응용 프로그램을 작성하고 실행시키기 위한 오픈소스 프레임워크
    - 접근
    - 견고성
    - 확장 가능성
    - 간단성

- Map/Reduce 로 간단한 프로그램이의 확장

### Hadoop 의 데몬들과 그 역할
- **NameNode** : HDFS의 master 역할을 하며, slave인 DataNode 데몬에게 I/O 작업을 지시한다. HDFS 의 일종의 기록원이다. 어떻게 파일이 블록 단위로 나누어져 있는지, 어느 노드가 해당 블록을 가지고 있는지와 분산 파일 시스템의 전반적인 상태를 알고 있다.
- **DataNode** : slave 머신에는 DataNode 데몬이 존재하는데, 로컬 파일 시스템에 위치한 파일에 HDFS 블록을 기록하거나 해당 파일을 읽는 등의 단순한 기능을 수행함.
- **Secondary NameNode** : 클러스터로 구성된 HDFS 의 상태를 모니터링하는 보조 성격을 가진 데몬. 각 클러스터는 하나의 SNN을 가지는데, 보통은 전용 머신에서 실행됨. 주기적으로 HDFS 메타데이터의 스냅샷을 찍어 데이터 손실과 시스템의 정지 시간을 최소화하는데 사용됨
- **JobTracker** : 클러스터 노드에서 실행되는 사용자 어플리케이션들을 관리함. 하둡 클러스터에는 하나의 JobTracker 데몬만 존재, 보통 master 노드에서 실행.
- **TaskTracker** : 각 slave 노드에 할당된 작업의 실행을 담당함 JobTracker 가 할당한 개별 작업을 실행한다. Slave 노드에는 TaskTracker 하나만 존재하며, 이 하나가 여러개의 JVM을 생성해서 다수의 map/reduce 작업을 병렬 처리할수 있다. 계속적으로 JobTracker 와 통신하며, 통신 실패시 JobTracker는 TaskTracker 에 문제가 생긴 것으로 간주하고 해당 작업을 클러스터 내에 위치한 다른 노드에 할당한다.

### 전형적인 Hadoop 클러스터의 구조
![structure_of_hadoop_cluster](/img/structure_of_hadoop_cluster.JPG)

### Hadoop 클러스터를 위한 SSH 의 설정
- master 노드는 클러스터에 위치한 다른 모든 노드들에 접근할수 있어야 하는데, 이런 접근을 위해 SSH 를 사용한다.
- 하둡에서는 모든 노드가 동일한 사용자명을 가진다.

### Hadoop 파일 다루기
- 기본적인 파일 명령어
    - `hadoop fs -cmd <args>`
- 파일 및 디렉토리 추가 : `hadoop fs -mkdir <path>`
- 디렉토리 확인 : `hadoop fs -ls -R <path>`
- 로컬 파일 hfs 로 복사 : `hadoop fs -put example.txt /user/junyoung`
